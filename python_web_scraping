#DISTANCE
import pandas as pd
import re
from selenium import webdriver
from selenium.webdriver.chrome.options import Options

# Path to ChromeDriver executable
chrome_driver_path = r'C:\Users\alex_\Downloads\chromedriver-win64\chromedriver-win64\chromedriver.exe'

# Set up Chrome options
chrome_options = Options()
chrome_options.add_argument('--headless')  # Run headless Chrome (optional)

# Initialize WebDriver
driver = webdriver.Chrome(
    executable_path=chrome_driver_path,  # Path to the ChromeDriver executable
    options=chrome_options
)

# Open the webpage
driver.get('https://www.pgatour.com/stats/detail/101')

# Find the div using the CSS selector
css_selector = '#__next > div.css-1hs4aw1 > div > div.css-i5hv4r > main > div > div:nth-child(9)'
div = driver.find_element_by_css_selector(css_selector)

# Gather div_text
div_text=div.text

# Regular expression to remove 'Tour Average' and the following numeric value
# This pattern captures 'Tour Average' and any numeric values that follow, including optional newlines
pattern = re.compile(r'Tour Average\s+[\d.,]+\s*\n?')

# Apply regex substitution to remove 'Tour Average' and the numeric value
cleaned_text = pattern.sub('', div_text).strip()  # .strip() to remove any leading/trailing whitespace

# Print the cleaned text
print(cleaned_text.splitlines()[:10])

# Define keywords to remove (can be adjusted based on needs)
keywords_to_remove = [
    'All Players', 'RANK', 'PLAYER', 'AVG', 
    'TOTAL DISTANCE', 'TOTAL DRIVES'
]

# Function to remove specific keywords
def clean_text(text, keywords):
    lines = text.splitlines()
    cleaned_lines = [line for line in lines if not any(keyword in line for keyword in keywords)]
    return "\n".join(cleaned_lines)

# Clean the text by removing lines containing specific keywords
cleaned_text = clean_text(cleaned_text, keywords_to_remove)

# Print the cleaned text
print(cleaned_text.splitlines()[:10])

# Define the updated headers (removing 'All Players')
headers = ['Rank', 'Change', 'Player', 'Avg', 'Total Distance', 'Total Drives']

# Function to handle multi-word entries correctly
def extract_values_from_line(line):
# Split line by a predefined number of spaces or other delimiter
# Assuming space-separated values, we use regex to split on multiple spaces and handle quotes for multi-word entries
    return re.split(r'\s{2,}', line.strip())  # Split on 2 or more spaces

# Split the cleaned text into individual values
values = [cleaned_text]
for line in cleaned_text.splitlines():
    values.extend(extract_values_from_line(line))

# Create rows from values
rows = [values[i:i + len(headers)] for i in range(1, len(values), len(headers))]

# Create the DataFrame
dist = pd.DataFrame(rows, columns=headers)

# Print the DataFrame
print(dist)

csv=r'C:\Users\alex_\OneDrive\PGA Predictor\Python\dist.csv'
dist.to_csv(csv, index=False)

file_path = r'C:\Users\alex_\OneDrive\PGA Predictor\Python\dist.csv'
os.startfile(file_path)












#ACCURACY

import pandas as pd
import re
from selenium import webdriver
from selenium.webdriver.chrome.options import Options

# Path to ChromeDriver executable
chrome_driver_path = r'C:\Users\alex_\Downloads\chromedriver-win64\chromedriver-win64\chromedriver.exe'

# Set up Chrome options
chrome_options = Options()
chrome_options.add_argument('--headless')  # Run headless Chrome (optional)

# Initialize WebDriver
driver = webdriver.Chrome(
    executable_path=chrome_driver_path,  # Path to the ChromeDriver executable
    options=chrome_options
)

# Open the webpage
driver.get('https://www.pgatour.com/stats/detail/102')

# Find the div using the CSS selector
css_selector = '#__next > div.css-1hs4aw1 > div > div.css-i5hv4r > main > div > div:nth-child(9) > div.css-0'
div = driver.find_element_by_css_selector(css_selector)

# Gather div_text
div_text=div.text

# Regular expression to remove 'Tour Average' and the following numeric value
# This pattern captures 'Tour Average' and any numeric values that follow, including optional newlines
pattern = re.compile(r'Tour Average\s+[\d.,]+\s*%?\n?')

# Apply regex substitution to remove 'Tour Average' and the numeric value
cleaned_text = pattern.sub('', div_text).strip()  # .strip() to remove any leading/trailing whitespace

# Print the cleaned text
print(cleaned_text.splitlines()[:10])

# Define keywords to remove (can be adjusted based on needs)
keywords_to_remove = [
    'All Players', 'RANK', 'PLAYER',
    'FAIRWAYS HIT', 'POSSIBLE FAIRWAYS'
]

# Function to remove specific keywords
def clean_text(text, keywords):
    lines = text.splitlines()  # Split the text into lines
    cleaned_lines = [
        line for line in lines
        if not any(keyword in line for keyword in keywords)  # Filter out lines with keywords
    ]
    cleaned_text = "\n".join(cleaned_lines)  # Join the cleaned lines into a single string
    return cleaned_text  # Return the cleaned text

# Clean the text by removing lines containing specific keywords
cleaned_text = clean_text(cleaned_text, keywords_to_remove)

# Remove only the first occurrence of %
cleaned_text = re.sub(r'%\s*', '', cleaned_text, 1)

# Print the cleaned text
print(cleaned_text.splitlines()[:10])

# Define the updated headers (removing 'All Players')
headers = ['Rank', 'Change', 'Player', '%', 'Fairways Hit', 'Possible Fairways']

# Function to handle multi-word entries correctly
def extract_values_from_line(line):
# Split line by a predefined number of spaces or other delimiter
# Assuming space-separated values, we use regex to split on multiple spaces and handle quotes for multi-word entries
    return re.split(r'\s{2,}', line.strip())  # Split on 2 or more spaces

# Split the cleaned text into individual values
values = [cleaned_text]
for line in cleaned_text.splitlines():
    values.extend(extract_values_from_line(line))

# Create rows from values
rows = [values[i:i + len(headers)] for i in range(1, len(values), len(headers))]

# Create the DataFrame
acc = pd.DataFrame(rows, columns=headers)

# Print the DataFrame
print(acc)

csv=r'C:\Users\alex_\OneDrive\PGA Predictor\Python\acc.csv'
acc.to_csv(csv, index=False)

file_path = r'C:\Users\alex_\OneDrive\PGA Predictor\Python\acc.csv'
os.startfile(file_path)














#APPROACH

import pandas as pd
import re
from selenium import webdriver
from selenium.webdriver.chrome.options import Options

# Path to ChromeDriver executable
chrome_driver_path = r'C:\Users\alex_\Downloads\chromedriver-win64\chromedriver-win64\chromedriver.exe'

# Set up Chrome options
chrome_options = Options()
chrome_options.add_argument('--headless')  # Run headless Chrome (optional)

# Initialize WebDriver
driver = webdriver.Chrome(
    executable_path=chrome_driver_path,  # Path to the ChromeDriver executable
    options=chrome_options
)

# Open the webpage
driver.get('https://www.pgatour.com/stats/detail/02568')

# Find the div using the CSS selector
css_selector = '#__next > div.css-1hs4aw1 > div > div.css-i5hv4r > main > div > div:nth-child(9) > div.css-0'
div = driver.find_element_by_css_selector(css_selector)

# Gather div_text
div_text=div.text

# Regular expression to remove 'Tour Average' and the following numeric value
# This pattern captures 'Tour Average' and any numeric values that follow, including optional newlines
pattern = re.compile(r'Tour Average\s+[\d.,]+\s*%?\n?')

# Apply regex substitution to remove 'Tour Average' and the numeric value
cleaned_text = pattern.sub('', div_text).strip()  # .strip() to remove any leading/trailing whitespace

# Print the cleaned text
print(cleaned_text.splitlines()[:10])

# Define keywords to remove (can be adjusted based on needs)
keywords_to_remove = [
    'All Players', 'RANK', 'PLAYER',
    'AVG', 'TOTAL SG:APP', 'MEASURED ROUNDS'
]

# Function to remove specific keywords
def clean_text(text, keywords):
    lines = text.splitlines()  # Split the text into lines
    cleaned_lines = [
        line for line in lines
        if not any(keyword in line for keyword in keywords)  # Filter out lines with keywords
    ]
    cleaned_text = "\n".join(cleaned_lines)  # Join the cleaned lines into a single string
    return cleaned_text  # Return the cleaned text

# Clean the text by removing lines containing specific keywords
cleaned_text = clean_text(cleaned_text, keywords_to_remove)

# Print the cleaned text
print(cleaned_text.splitlines()[:10])

# Define the updated headers (removing 'All Players')
headers = ['Rank', 'Change', 'Player', 'Avg', 'Total SG:APP', 'Measured Rounds']

# Function to handle multi-word entries correctly
def extract_values_from_line(line):
# Split line by a predefined number of spaces or other delimiter
# Assuming space-separated values, we use regex to split on multiple spaces and handle quotes for multi-word entries
    return re.split(r'\s{2,}', line.strip())  # Split on 2 or more spaces

# Split the cleaned text into individual values
values = [cleaned_text]
for line in cleaned_text.splitlines():
    values.extend(extract_values_from_line(line))

# Create rows from values
rows = [values[i:i + len(headers)] for i in range(1, len(values), len(headers))]

# Create the DataFrame
app = pd.DataFrame(rows, columns=headers)

# Print the DataFrame
print(app)

csv=r'C:\Users\alex_\OneDrive\PGA Predictor\Python\app.csv'
app.to_csv(csv, index=False)

file_path = r'C:\Users\alex_\OneDrive\PGA Predictor\Python\app.csv'
os.startfile(file_path)

















#ARG

import pandas as pd
import re
from selenium import webdriver
from selenium.webdriver.chrome.options import Options

# Path to ChromeDriver executable
chrome_driver_path = r'C:\Users\alex_\Downloads\chromedriver-win64\chromedriver-win64\chromedriver.exe'

# Set up Chrome options
chrome_options = Options()
chrome_options.add_argument('--headless')  # Run headless Chrome (optional)

# Initialize WebDriver
driver = webdriver.Chrome(
    executable_path=chrome_driver_path,  # Path to the ChromeDriver executable
    options=chrome_options
)

# Open the webpage
driver.get('https://www.pgatour.com/stats/detail/02569')

# Find the div using the CSS selector
css_selector = '#__next > div.css-1hs4aw1 > div > div.css-i5hv4r > main > div > div:nth-child(9) > div.css-0'
div = driver.find_element_by_css_selector(css_selector)

# Gather div_text
div_text=div.text

# Regular expression to remove 'Tour Average' and the following numeric value
# This pattern captures 'Tour Average' and any numeric values that follow, including optional newlines
pattern = re.compile(r'Tour Average\s+[\d.,]+\s*%?\n?')

# Apply regex substitution to remove 'Tour Average' and the numeric value
cleaned_text = pattern.sub('', div_text).strip()  # .strip() to remove any leading/trailing whitespace

# Print the cleaned text
print(cleaned_text.splitlines()[:10])

# Define keywords to remove (can be adjusted based on needs)
keywords_to_remove = [
    'All Players', 'RANK', 'PLAYER',
    'AVG', 'TOTAL SG:ARG', 'MEASURED ROUNDS'
]

# Function to remove specific keywords
def clean_text(text, keywords):
    lines = text.splitlines()  # Split the text into lines
    cleaned_lines = [
        line for line in lines
        if not any(keyword in line for keyword in keywords)  # Filter out lines with keywords
    ]
    cleaned_text = "\n".join(cleaned_lines)  # Join the cleaned lines into a single string
    return cleaned_text  # Return the cleaned text

# Clean the text by removing lines containing specific keywords
cleaned_text = clean_text(cleaned_text, keywords_to_remove)

# Print the cleaned text
print(cleaned_text.splitlines()[:10])

# Define the updated headers (removing 'All Players')
headers = ['Rank', 'Change', 'Player', 'Avg', 'Total SG:ARG', 'Measured Rounds']

# Function to handle multi-word entries correctly
def extract_values_from_line(line):
# Split line by a predefined number of spaces or other delimiter
# Assuming space-separated values, we use regex to split on multiple spaces and handle quotes for multi-word entries
    return re.split(r'\s{2,}', line.strip())  # Split on 2 or more spaces

# Split the cleaned text into individual values
values = [cleaned_text]
for line in cleaned_text.splitlines():
    values.extend(extract_values_from_line(line))

# Create rows from values
rows = [values[i:i + len(headers)] for i in range(1, len(values), len(headers))]

# Create the DataFrame
arg = pd.DataFrame(rows, columns=headers)

# Print the DataFrame
print(arg)

csv=r'C:\Users\alex_\OneDrive\PGA Predictor\Python\arg.csv'
arg.to_csv(csv, index=False)

file_path = r'C:\Users\alex_\OneDrive\PGA Predictor\Python\arg.csv'
os.startfile(file_path)















#PUTT

import pandas as pd
import re
from selenium import webdriver
from selenium.webdriver.chrome.options import Options

# Path to ChromeDriver executable
chrome_driver_path = r'C:\Users\alex_\Downloads\chromedriver-win64\chromedriver-win64\chromedriver.exe'

# Set up Chrome options
chrome_options = Options()
chrome_options.add_argument('--headless')  # Run headless Chrome (optional)

# Initialize WebDriver
driver = webdriver.Chrome(
    executable_path=chrome_driver_path,  # Path to the ChromeDriver executable
    options=chrome_options
)

# Open the webpage
driver.get('https://www.pgatour.com/stats/detail/02564')

# Find the div using the CSS selector
css_selector = '#__next > div.css-1hs4aw1 > div > div.css-i5hv4r > main > div > div:nth-child(9) > div.css-0'
div = driver.find_element_by_css_selector(css_selector)

# Gather div_text
div_text=div.text

# Regular expression to remove 'Tour Average' and the following numeric value
# This pattern captures 'Tour Average' and any numeric values that follow, including optional newlines
pattern = re.compile(r'Tour Average\s+[\d.,]+\s*%?\n?')

# Apply regex substitution to remove 'Tour Average' and the numeric value
cleaned_text = pattern.sub('', div_text).strip()  # .strip() to remove any leading/trailing whitespace

# Print the cleaned text
print(cleaned_text.splitlines()[:10])

# Define keywords to remove (can be adjusted based on needs)
keywords_to_remove = [
    'All Players', 'RANK', 'PLAYER',
    'AVG', 'TOTAL SG:PUTTING', 'MEASURED ROUNDS'
]

# Function to remove specific keywords
def clean_text(text, keywords):
    lines = text.splitlines()  # Split the text into lines
    cleaned_lines = [
        line for line in lines
        if not any(keyword in line for keyword in keywords)  # Filter out lines with keywords
    ]
    cleaned_text = "\n".join(cleaned_lines)  # Join the cleaned lines into a single string
    return cleaned_text  # Return the cleaned text

# Clean the text by removing lines containing specific keywords
cleaned_text = clean_text(cleaned_text, keywords_to_remove)

# Print the cleaned text
print(cleaned_text.splitlines()[:10])

# Define the updated headers (removing 'All Players')
headers = ['Rank', 'Change', 'Player', 'Avg', 'Total SG:PUTT', 'Measured Rounds']

# Function to handle multi-word entries correctly
def extract_values_from_line(line):
# Split line by a predefined number of spaces or other delimiter
# Assuming space-separated values, we use regex to split on multiple spaces and handle quotes for multi-word entries
    return re.split(r'\s{2,}', line.strip())  # Split on 2 or more spaces

# Split the cleaned text into individual values
values = [cleaned_text]
for line in cleaned_text.splitlines():
    values.extend(extract_values_from_line(line))

# Create rows from values
rows = [values[i:i + len(headers)] for i in range(1, len(values), len(headers))]

# Create the DataFrame
putt = pd.DataFrame(rows, columns=headers)

# Print the DataFrame
print(putt)

csv=r'C:\Users\alex_\OneDrive\PGA Predictor\Python\putt.csv'
putt.to_csv(csv, index=False)

file_path = r'C:\Users\alex_\OneDrive\PGA Predictor\Python\arg.csv'
os.startfile(file_path)



















#SG

import pandas as pd
import re
from selenium import webdriver
from selenium.webdriver.chrome.options import Options

# Path to ChromeDriver executable
chrome_driver_path = r'C:\Users\alex_\Downloads\chromedriver-win64\chromedriver-win64\chromedriver.exe'

# Set up Chrome options
chrome_options = Options()
chrome_options.add_argument('--headless')  # Run headless Chrome (optional)

# Initialize WebDriver
driver = webdriver.Chrome(
    executable_path=chrome_driver_path,  # Path to the ChromeDriver executable
    options=chrome_options
)

# Open the webpage
driver.get('https://www.pgatour.com/stats/detail/02675')

# Find the div using the CSS selector
css_selector = '#__next > div.css-1hs4aw1 > div > div.css-i5hv4r > main > div > div:nth-child(9) > div.css-0'
div = driver.find_element_by_css_selector(css_selector)

# Gather div_text
div_text=div.text

# Regular expression to remove 'Tour Average' and the following numeric value
# This pattern captures 'Tour Average' and any numeric values that follow, including optional newlines
pattern = re.compile(r'Tour Average\s+[\d.,]+\s*%?\n?')

# Apply regex substitution to remove 'Tour Average' and the numeric value
cleaned_text = pattern.sub('', div_text).strip()  # .strip() to remove any leading/trailing whitespace

# Print the cleaned text
print(cleaned_text.splitlines()[:10])

# Define keywords to remove (can be adjusted based on needs)
keywords_to_remove = [
    'All Players', 'RANK', 'PLAYER',
    'AVG', 'TOTAL SG:T', 'TOTAL SG:T2G', 'TOTAL SG:P', 'MEASURED ROUNDS'
]

# Function to remove specific keywords
def clean_text(text, keywords):
    lines = text.splitlines()  # Split the text into lines
    cleaned_lines = [
        line for line in lines
        if not any(keyword in line for keyword in keywords)  # Filter out lines with keywords
    ]
    cleaned_text = "\n".join(cleaned_lines)  # Join the cleaned lines into a single string
    return cleaned_text  # Return the cleaned text

# Clean the text by removing lines containing specific keywords
cleaned_text = clean_text(cleaned_text, keywords_to_remove)

# Print the cleaned text
print(cleaned_text.splitlines()[:10])

# Define the updated headers (removing 'All Players')
headers = ['Rank', 'Change', 'Player', 'Avg', 'Total SG:T', 'Total SG:T2G', 'Total SG:P', 'Measured Rounds']

# Function to handle multi-word entries correctly
def extract_values_from_line(line):
# Split line by a predefined number of spaces or other delimiter
# Assuming space-separated values, we use regex to split on multiple spaces and handle quotes for multi-word entries
    return re.split(r'\s{2,}', line.strip())  # Split on 2 or more spaces

# Split the cleaned text into individual values
values = [cleaned_text]
for line in cleaned_text.splitlines():
    values.extend(extract_values_from_line(line))

# Create rows from values
rows = [values[i:i + len(headers)] for i in range(1, len(values), len(headers))]

# Create the DataFrame
sg = pd.DataFrame(rows, columns=headers)

# Print the DataFrame
print(sg)

csv=r'C:\Users\alex_\OneDrive\PGA Predictor\Python\sg.csv'
sg.to_csv(csv, index=False)

file_path = r'C:\Users\alex_\OneDrive\PGA Predictor\Python\putt.csv'
os.startfile(file_path)


















#Merge

import pandas as pd

# Merge DataFrames while keeping 'Player' and all 'Avg' columns
pgamodel = (
    pd.merge(dist[['Player', 'Avg']], acc[['Player', '%']], on='Player', how='inner', suffixes=('_dist', '_acc'))
    .merge(app[['Player', 'Avg']], on='Player', how='inner', suffixes=('', '_app'))
    .merge(arg[['Player', 'Avg']], on='Player', how='inner', suffixes=('', '_arg'))
    .merge(putt[['Player', 'Avg']], on='Player', how='inner', suffixes=('', '_putt'))
    .merge(sg[['Player', 'Avg']], on='Player', how='inner', suffixes=('', '_sg'))
)

print(pgamodel)

# Remove '%' symbol and convert to numeric
if '%' in pgamodel.columns:
    pgamodel['%'] = pgamodel['%'].str.replace('%', '', regex=False).astype(float)

# Convert object columns to numeric where possible, excluding 'Player'
for col in pgamodel.columns:
    if col != 'Player' and pgamodel[col].dtype == 'object':
        try:
            pgamodel[col] = pd.to_numeric(pgamodel[col], errors='coerce')
        except ValueError:
            # Columns that cannot be converted to numeric will be left as is
            pass

# Now, numeric columns can be scaled
numeric_columns = pgamodel.select_dtypes(include=['float64', 'int64']).columns.difference(['Player'])

def min_max_scaling(series):
    min_val = series.min()
    max_val = series.max()
    if max_val != min_val:
        return (series - min_val) / (max_val - min_val)
    else:
        return series  # Return the original series if all values are the same

# Apply min-max scaling to numeric columns
pgamodel[numeric_columns] = pgamodel[numeric_columns].apply(min_max_scaling)

print(pgamodel)

#Add columns
pgamodel['dg'] = pd.NA
pgamodel['radar'] = pd.NA
pgamodel['bdg'] = pd.NA
pgamodel['bradar'] = pd.NA
pgamodel['dgcr'] = pd.NA
pgamodel['radarcr'] = pd.NA
pgamodel['bdgcr'] = pd.NA
pgamodel['bradarcr'] = pd.NA
pgamodel['win'] = pd.NA
pgamodel['t10'] = pd.NA
pgamodel['sgt5'] = pd.NA

pga=pgamodel.copy()

#Rename columns
pga=pgamodel.rename(columns = {'Avg':'dist', '%':'acc', 'Avg_app':'app', 
'Avg_arg':'arg', 'Avg_putt':'putt', 'Avg_sg':'sg'})
